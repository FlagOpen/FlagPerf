# 配置和使用文档请参考: https://github.com/FlagOpen/FlagPerf/pull/318
name: klx-training-pre-pr-check

on:
  workflow_dispatch:
    inputs:
      case1x1:
        description: '1x1 case name that filled into test_conf.py (empty means not to execute)'
        default: 'model:framework:hardwareID:1:1:1'
      case1x8:
        description: '1x8 case name that filled into test_conf.py (empty means not to execute)'
        default: 'model:framework:hardwareID:1:8:1'
      dataset_path:
        description: 'dataset path filled into test_conf.py'
        default: 'dataset path'
        required: true
jobs:
  run-klx-training-test:
    runs-on: [ self-hosted, klx, r480 ]
    steps:
      # 1. Checkout
      - name: Checkout code
        uses: actions/checkout@master
        with:
          fetch-depth: 1

      # 2. Setup basic information in test_conf.py
      - name: Setup test_conf.py
        run: |
          echo "VENDOR = 'kunlunxin'" >> training/run_benchmarks/config/test_conf.py &&
          echo "ACCE_CONTAINER_OPT = '--device=/dev/xpu0 --device=/dev/xpu1 --device=/dev/xpu2 --device=/dev/xpu3 --device=/dev/xpu4 --device=/dev/xpu5 --device=/dev/xpu6 --device=/dev/xpu7 --device=/dev/xpuctrl'" >> training/run_benchmarks/config/test_conf.py &&
          echo "ACCE_VISIBLE_DEVICE_ENV_NAME = 'XPU_VISIBLE_DEVICES'" >> training/run_benchmarks/config/test_conf.py &&
          echo "PIP_SOURCE = 'https://pypi.tuna.tsinghua.edu.cn/simple'" &&
          echo "FLAGPERF_PATH = '${PWD}/training'" >> training/run_benchmarks/config/test_conf.py &&
          echo "FLAGPERF_LOG_PATH = '${PWD}/training/result/'" >> training/run_benchmarks/config/test_conf.py &&
          cat training/run_benchmarks/config/test_conf.py

      # 3. Setup cases in test_conf.py
      - name: Setup 1x1 case and 1x8 case in test_conf.py
        if: ${{ inputs.case1x1 != '' && inputs.case1x8 != '' }}
        run: |
          echo "CASES = { '${{ inputs.case1x1 }}' : '${{ inputs.dataset_path }}', '${{ inputs.case1x8 }}' : '${{ inputs.dataset_path }}' }" >> training/run_benchmarks/config/test_conf.py &&
          cat training/run_benchmarks/config/test_conf.py
      - name: Setup 1x1 case in test_conf.py
        if: ${{ inputs.case1x1 != '' && inputs.case1x8 == '' }}
        run: |
          echo "CASES = { '${{ inputs.case1x1 }}' : '${{ inputs.dataset_path }}' }" >> training/run_benchmarks/config/test_conf.py &&
          cat training/run_benchmarks/config/test_conf.py
      - name: Setup 1x8 case in test_conf.py
        if: ${{ inputs.case1x1 == '' && inputs.case1x8 != '' }}
        run: |
          echo "CASES = { '${{ inputs.case1x1 }}' : '${{ inputs.dataset_path }}' }" >> training/run_benchmarks/config/test_conf.py &&
          cat training/run_benchmarks/config/test_conf.py
      - name: Setup empty cases in test_conf.py
        if: ${{ inputs.case1x1 == '' && inputs.case1x8 == '' }}
        run: |
          echo "At least one of case1x1 and case1x8 is not empty！" &&
          ls non_existent_file.txt

      # 4. Setup cluster_conf.py
      - name: Setup cluster_conf.py
        run: |
          echo "HOSTS = ['127.0.0.1']" >> training/run_benchmarks/config/cluster_conf.py &&
          cat training/run_benchmarks/config/cluster_conf.py

      # 5. Run test
      - name: Run test
        run: |
          pushd training &&
          python3 run_benchmarks/run.py 2>&1 | tee tmp_run.log &&
          popd

      # 6. Verify test result
      # https://docs.github.com/en/actions/using-workflows/workflow-commands-for-github-actions#setting-an-output-parameter
      - name: Get run result name
        id: run-result-name
        run: echo "RUN_RESULT_NAME=$(cat training/tmp_run.log | grep 'Initialize logger with log path:' | egrep -o 'run[0-9]+')"  >> "$GITHUB_OUTPUT"

      - name: Verify 1x1 case result
        if: ${{ inputs.case1x1 != '' }}
        env:
          RUN_RESULT_NAME: ${{ steps.run-result-name.outputs.RUN_RESULT_NAME }}
        run: |
          cat training/result/${RUN_RESULT_NAME}/${{ inputs.case1x1 != '' }}/round1/127.0.0.1_noderank0/rank0.out.log
          grep "FINISHED" "training/result/${RUN_RESULT_NAME}/${{ inputs.case1x1 != '' }}/round1/127.0.0.1_noderank0/rank0.out.log"

      - name: Verify 1x8 case result
        if: ${{ inputs.case1x8 != '' }}
        env:
          RUN_RESULT_NAME: ${{ steps.run-result-name.outputs.RUN_RESULT_NAME }}
        run: |
          cat training/result/${RUN_RESULT_NAME}/${{ inputs.case1x8 != '' }}/round1/127.0.0.1_noderank0/rank0.out.log
          grep "FINISHED" "training/result/${RUN_RESULT_NAME}/${{ inputs.case1x8 != '' }}/round1/127.0.0.1_noderank0/rank0.out.log"

      # 7. Clean job
      - name: Remove tmp_run.log, restore test_conf.py and cluster_conf.py
        run: |
          rm -f training/tmp_run.log &&
          git checkout training/run_benchmarks/config/test_conf.py &&
          git checkout training/run_benchmarks/config/cluster_conf.py
