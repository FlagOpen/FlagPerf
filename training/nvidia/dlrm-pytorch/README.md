### 数据集下载

[数据集下载](../../benchmarks/dlrm/README.md#数据集下载地址)

### Nvidia GPU配置与运行信息参考
#### 环境配置

- ##### 硬件环境
    - 机器型号: NVIDIA DGX A100(40G) 
    - 加速卡型号: NVIDIA_A100-SXM4-40GB
    - CPU型号: AMD EPYC7742-64core@1.5G
    - 多机网络类型、带宽: InfiniBand，200Gb/s

- ##### 软件环境
   - OS版本：Ubuntu 20.04
   - OS kernel版本: 5.4.0-113-generic     
   - 加速卡驱动版本：470.129.06
   - Docker 版本：20.10.16
   - 训练框架版本：pytorch-1.10.0a0+0aef44c
   - 依赖软件版本：无


### 运行情况

* 通用指标

| 指标名称       | 指标值                  | 特殊说明                                                      |
| -------------- | ----------------------- | ------------------------------------------------------------- |
| 任务类别       | Recommendation Systems  |                                                               |
| 模型           | dlrm                    |                                                               |
| 数据集         | Criteo Terabyte Dataset |                                                               |
| 数据精度       | precision,见“性能指标”  | 可选fp32/amp/fp16                                             |
| 超参修改       | fix_hp,见“性能指标”     | 跑满硬件设备评测吞吐量所需特殊超参                            |
| 硬件设备简称   | nvidia A100             |                                                               |
| 硬件存储使用   | mem,见“性能指标”        | 通常称为“显存”,单位为GiB                                      |
| 端到端时间     | e2e_time,见“性能指标”   | 总时间+Perf初始化等时间                                       |
| 总吞吐量       | p_whole,见“性能指标”    | 实际训练样本数除以总时间(performance_whole)                   |
| 训练吞吐量     | p_train,见“性能指标”    | 不包含每个epoch末尾的评估部分耗时                             |
| **计算吞吐量** | **p_core,见“性能指标”** | 不包含数据IO部分的耗时(p3>p2>p1)                              |
| 训练结果       | auc,见“性能指标”        | AUC（Area Under the Receiver Operating Characteristic Curve） |
| 额外修改项     | 无                      |                                                               |

* 性能指标

| 配置              | precision | fix_hp | e2e_time | p_whole  | p_train  | p_core   | auc          | mem       |
| ----------------- | --------- | ------ | -------- | -------- | -------- | -------- | ------------ | --------- |
| A100单机单卡(1x1) | amp       | /      | 1152     | 7292588  | 7466400  | 8493416  | 0.8026/0.802 | 20.5/40.0 |
| A100单机8卡(1x8)  | amp       | /      | 3485     | 19331640 | 19744146 | 23773543 | 0.8024/0.802 | 9.8/40.0  |
| A100两机8卡(2x8)  | amp       | /      | 4779     | 28173936 | 29432923 | 34934809 | 0.8025/0.802 | 7.1/40.0  |
| A100单机8卡(1x8) | amp       | bs=2097152 | /        | 106141201 | 110380548 | 145088266 | /            | 33.4/40.0 |
| A100单机单卡(1x1) | amp       | bs=262144  | /        | 7502493   | 7655769   | 9036591   | /            | 29.3/40.0 |
| A100两机8卡(2x8) | amp       | bs=2752512 | /        | 71511910  | 72766954  | 80541553  | /            | 23.9/40.0 |

`注:all2all 算子需要从每个进程到其他每个进程的通信。换句话说，在 N–GPU 集群中，作为 all2all 操作的一部分交换的消息数是 O(N^2).[ref](https://developer.nvidia.com/zh-cn/blog/doubling-all2all-performance-with-nvidia-collective-communication-library-2-12/)
对于DLRM模型的多机训练，模型参数需要在不同的机器之间进行同步，这会产生额外的通信开销.如果网络带宽不足，或者通信效率不高，这种开销可能会导致多机训练的性能低于单机训练。
改变超参后，因embedding table的模型并行和数据并行的hybrid并行方案，以及all2all通信，导致该模型为通信而非算力bound，导致以上的性能结果。`