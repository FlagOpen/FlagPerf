from torch import nn


def model_to_fp16(model, config):
    return model


def create_grad_scaler(args):
    return None